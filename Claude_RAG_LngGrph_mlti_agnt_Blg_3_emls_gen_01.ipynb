{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfczecokSibAxBq7yxSMlm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RexPersicus/ChatGPT_Prompt_Eng_01/blob/main/Claude_RAG_LngGrph_mlti_agnt_Blg_3_emls_gen_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sigj6o0IVm59",
        "outputId": "0f75b95f-105d-44fe-ecd4-f8196afbb910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.53-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-magic\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.40-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.11)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.1.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading langchain_openai-0.2.10-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.53-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
            "Downloading chromadb-0.5.20-py3-none-any.whl (617 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.7-py3-none-any.whl (35 kB)\n",
            "Downloading langgraph_sdk-0.1.40-py3-none-any.whl (29 kB)\n",
            "Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: docx2txt, pypika\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=655a406db3cdfa94f2b65757ee725a61374383505e69f13a13b8135bff44a144\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=301113e49b0122f8a31962ced7a1702c6a57a0634f2e37ce88daf01f7bfed69f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built docx2txt pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, docx2txt, websockets, uvloop, uvicorn, SQLAlchemy, python-magic, python-dotenv, pyproject_hooks, PyPDF2, protobuf, overrides, opentelemetry-util-http, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, tiktoken, starlette, posthog, opentelemetry-proto, coloredlogs, build, tavily-python, pydantic-settings, opentelemetry-exporter-otlp-proto-common, onnxruntime, langgraph-sdk, kubernetes, fastapi, dataclasses-json, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, langchain-openai, opentelemetry-instrumentation-fastapi, langgraph, langchain, langchain-community, chromadb\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 SQLAlchemy-2.0.35 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.20 coloredlogs-15.0.1 dataclasses-json-0.6.7 docx2txt-0.8 durationpy-0.9 fastapi-0.115.5 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-31.0.0 langchain-0.3.9 langchain-community-0.3.8 langchain-core-0.3.21 langchain-openai-0.2.10 langgraph-0.2.53 langgraph-checkpoint-2.0.7 langgraph-sdk-0.1.40 marshmallow-3.23.1 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.0 pydantic-settings-2.6.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 python-magic-0.4.27 starlette-0.41.3 tavily-python-0.5.0 tiktoken-0.8.0 typing-inspect-0.9.0 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1\n"
          ]
        }
      ],
      "source": [
        "#========================================================================================================================================================\n",
        "# This code Uses multi-agents in Langgraph and using Open AI GPT API and Tavily. I want to run the code in Google Colab. API Keys will be in a .env file.\n",
        "# This application analyses the information about a company that I will name, and provide recommendation on how to approach them for marketing our services.\n",
        "# This recommendation is in the form of a blog post with relevant sections and some action items at the end. The application will ask the name of the prospective\n",
        "# organization and will use a RAG file containing information about my company's services and background. Once it has created the recommendation blog post it\n",
        "# should ask the user if I want it to also generate emails for marketing my company's services to the prospective organization and if I say yes, it should create\n",
        "# the context of max 3 emails to 3 different key people in that organization. It can ask if I want to repeat this whole thing for another prospectice organization.\n",
        "# If I say yes, it should repeat the process.\n",
        "#========================================================================================================================================================\n",
        "\n",
        "\n",
        "# Install required packages\n",
        "!pip install python-dotenv langchain langchain-openai langchain-community tiktoken langgraph openai tavily-python chromadb python-magic PyPDF2 docx2txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "#------------------------------------------------------------------\n",
        "from typing import Dict, TypedDict, Annotated, Sequence, List\n",
        "#------------------------------------------------------------------\n",
        "from tavily import TavilyClient\n",
        "#------------------------------------------------------------------\n",
        "from langgraph.graph import Graph, MessageGraph\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "#from langgraph.prebuilt import ToolMessage\n",
        "\n",
        "# Import ToolMessage from langchain_core.messages instead of langgraph.prebuilt\n",
        "from langchain_core.messages import ToolMessage\n",
        "#------------------------------------------------------------------\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "#------------------------------------------------------------------\n",
        "import json\n",
        "import glob\n",
        "import PyPDF2\n",
        "import docx2txt\n",
        "import magic\n",
        "import operator\n",
        "\n",
        "from operator import add\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "V0gi43zfV78T"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize API clients\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "tavily_client = TavilyClient(api_key=tavily_api_key)\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    temperature=0.7,\n",
        "    api_key=openai_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "S8AKZxdPV75c"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentProcessor:\n",
        "    \"\"\"Handles reading and processing different types of documents\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def read_text_file(file_path: str) -> str:\n",
        "        \"\"\"Read plain text files\"\"\"\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "\n",
        "    @staticmethod\n",
        "    def read_pdf_file(file_path: str) -> str:\n",
        "        \"\"\"Read PDF files\"\"\"\n",
        "        text = \"\"\n",
        "        with open(file_path, 'rb') as f:\n",
        "            pdf_reader = PyPDF2.PdfReader(f)\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "\n",
        "    @staticmethod\n",
        "    def read_docx_file(file_path: str) -> str:\n",
        "        \"\"\"Read Word documents\"\"\"\n",
        "        return docx2txt.process(file_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_file_type(file_path: str) -> str:\n",
        "        \"\"\"Determine file type using python-magic\"\"\"\n",
        "        mime = magic.Magic(mime=True)\n",
        "        file_type = mime.from_file(file_path)\n",
        "        return file_type\n",
        "\n",
        "    @classmethod\n",
        "    def process_file(cls, file_path: str) -> str:\n",
        "        \"\"\"Process file based on its type\"\"\"\n",
        "        file_type = cls.get_file_type(file_path)\n",
        "\n",
        "        if 'text/plain' in file_type:\n",
        "            return cls.read_text_file(file_path)\n",
        "        elif 'application/pdf' in file_type:\n",
        "            return cls.read_pdf_file(file_path)\n",
        "        elif 'application/vnd.openxmlformats-officedocument.wordprocessingml.document' in file_type:\n",
        "            return cls.read_docx_file(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file type: {file_type}\")\n"
      ],
      "metadata": {
        "id": "BJUeg5brV728"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_rag() -> Chroma:\n",
        "    \"\"\"Initialize RAG system by reading all documents from uploads folder\"\"\"\n",
        "    uploads_path = 'uploads'\n",
        "\n",
        "    # Create uploads folder if it doesn't exist\n",
        "    if not os.path.exists(uploads_path):\n",
        "        os.makedirs(uploads_path)\n",
        "        print(f\"Created {uploads_path} directory. Please add your company documents there.\")\n",
        "        return None\n",
        "\n",
        "    # Get all files in uploads directory\n",
        "    files = glob.glob(os.path.join(uploads_path, '*'))\n",
        "\n",
        "    if not files:\n",
        "        print(f\"No files found in {uploads_path} directory. Please add your company documents.\")\n",
        "        return None\n",
        "\n",
        "    # Process all files\n",
        "    all_texts = []\n",
        "    doc_processor = DocumentProcessor()\n",
        "\n",
        "    print(\"Processing documents:\")\n",
        "    for file_path in files:\n",
        "        try:\n",
        "            print(f\"Reading {os.path.basename(file_path)}...\")\n",
        "            text = doc_processor.process_file(file_path)\n",
        "            all_texts.append(text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {str(e)}\")\n",
        "\n",
        "    if not all_texts:\n",
        "        print(\"No valid documents were processed.\")\n",
        "        return None\n",
        "\n",
        "    # Split texts into chunks\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = []\n",
        "    for text in all_texts:\n",
        "        chunks.extend(text_splitter.split_text(text))\n",
        "\n",
        "    # Create vector store\n",
        "    embeddings = OpenAIEmbeddings(api_key=openai_api_key)\n",
        "    vectorstore = Chroma.from_texts(chunks, embeddings)\n",
        "\n",
        "    print(f\"Successfully processed {len(files)} documents into {len(chunks)} chunks\")\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "VzIU075hV70-"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a setter function for non-list values\n",
        "def set_value(_, new_value):\n",
        "    return new_value\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[Dict], add]  # Use operator.add for lists\n",
        "    company_name: Annotated[str, set_value]  # Use our custom setter for simple values\n",
        "    research: Annotated[Dict, set_value]\n",
        "    analysis: Annotated[str, set_value]\n",
        "    blog_post: Annotated[str, set_value]\n",
        "    emails: Annotated[str, set_value]"
      ],
      "metadata": {
        "id": "zYcrU5_jWJvb"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def research_agent(state: AgentState):\n",
        "    \"\"\"Research agent that gathers information about the target company\"\"\"\n",
        "    print(f\"\\n🔍 Research Agent: Starting research for {state['company_name']}...\")\n",
        "\n",
        "    try:\n",
        "        search_results = tavily_client.search(\n",
        "            query=f\"{state['company_name']} company overview business model recent news\",\n",
        "            search_depth=\"advanced\"\n",
        "        )\n",
        "        print(\"✅ Research Agent: Successfully gathered company information\")\n",
        "\n",
        "        return {\n",
        "            \"messages\": state[\"messages\"] + [\n",
        "                {\"role\": \"assistant\", \"content\": f\"Research completed for {state['company_name']}\"}\n",
        "            ],\n",
        "            \"company_name\": state[\"company_name\"],\n",
        "            \"research\": search_results,\n",
        "            \"analysis\": state[\"analysis\"],\n",
        "            \"blog_post\": state[\"blog_post\"],\n",
        "            \"emails\": state[\"emails\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Research Agent Error: {str(e)}\")\n",
        "        return {\n",
        "            \"messages\": state[\"messages\"] + [\n",
        "                {\"role\": \"assistant\", \"content\": f\"Error during research: {str(e)}\"}\n",
        "            ],\n",
        "            \"company_name\": state[\"company_name\"],\n",
        "            \"research\": {},\n",
        "            \"analysis\": state[\"analysis\"],\n",
        "            \"blog_post\": state[\"blog_post\"],\n",
        "            \"emails\": state[\"emails\"]\n",
        "        }\n",
        "\n",
        "def analysis_agent(state: AgentState):\n",
        "    \"\"\"Analysis agent that processes research and RAG data\"\"\"\n",
        "    global vectorstore\n",
        "    print(f\"\\n🤔 Analysis Agent: Starting analysis of {state['company_name']}...\")\n",
        "\n",
        "    service_info = vectorstore.similarity_search(\n",
        "        f\"services relevant for {state['company_name']}\",\n",
        "        k=3\n",
        "    )\n",
        "    print(\"📚 Analysis Agent: Retrieved relevant service information\")\n",
        "\n",
        "    analysis_prompt = f\"\"\"\n",
        "    Based on the following information about {state['company_name']}:\n",
        "    {json.dumps(state['research'])}\n",
        "\n",
        "    And our company's relevant services:\n",
        "    {service_info}\n",
        "\n",
        "    Provide a detailed analysis of:\n",
        "    1. Company's current challenges and needs\n",
        "    2. How our services align with their needs\n",
        "    3. Key decision makers to target\n",
        "    4. Recommended approach strategy\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🔄 Analysis Agent: Generating analysis...\")\n",
        "    analysis_result = llm.invoke(analysis_prompt)\n",
        "    print(\"✅ Analysis Agent: Analysis completed\")\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [\n",
        "            {\"role\": \"assistant\", \"content\": \"Analysis completed\"}\n",
        "        ],\n",
        "        \"company_name\": state[\"company_name\"],\n",
        "        \"research\": state[\"research\"],\n",
        "        \"analysis\": analysis_result.content,\n",
        "        \"blog_post\": state[\"blog_post\"],\n",
        "        \"emails\": state[\"emails\"]\n",
        "    }\n",
        "\n",
        "def blog_writer_agent(state: AgentState):\n",
        "    \"\"\"Agent that creates the blog post recommendation\"\"\"\n",
        "    print(\"\\n✍️ Blog Writer Agent: Starting blog post creation...\")\n",
        "\n",
        "    print(f\"Debug - Analysis available: {bool(state['analysis'])}\")\n",
        "    print(f\"Debug - Analysis content preview: {state['analysis'][:200] if state['analysis'] else 'No analysis'}\")\n",
        "\n",
        "    blog_prompt = f\"\"\"\n",
        "    Create a detailed blog post about approaching {state['company_name']} for our services.\n",
        "    Use the following analysis: {state['analysis']}\n",
        "\n",
        "    Format the blog post with:\n",
        "    1. Compelling title\n",
        "    2. Executive summary\n",
        "    3. Company overview\n",
        "    4. Identified needs and challenges\n",
        "    5. Our solution fit\n",
        "    6. Recommended approach strategy\n",
        "    7. Action items\n",
        "\n",
        "    Make it engaging and professional.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🔄 Blog Writer Agent: Writing blog post...\")\n",
        "    blog_post = llm.invoke(blog_prompt)\n",
        "    print(f\"Debug - Blog post generated: {bool(blog_post.content)}\")\n",
        "    print(f\"Debug - Blog post preview: {blog_post.content[:200] if blog_post.content else 'No content'}\")\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [\n",
        "            {\"role\": \"assistant\", \"content\": \"Blog post generated\"}\n",
        "        ],\n",
        "        \"company_name\": state[\"company_name\"],\n",
        "        \"research\": state[\"research\"],\n",
        "        \"analysis\": state[\"analysis\"],\n",
        "        \"blog_post\": blog_post.content,  # Verify this is being set\n",
        "        \"emails\": state[\"emails\"]\n",
        "    }\n",
        "\n",
        "def email_writer_agent(state: AgentState):\n",
        "    \"\"\"Agent that creates marketing emails\"\"\"\n",
        "    print(\"\\n📧 Email Writer Agent: Starting email template creation...\")\n",
        "\n",
        "    email_prompt = f\"\"\"\n",
        "    Based on the analysis of {state['company_name']}:\n",
        "    {state['analysis']}\n",
        "\n",
        "    Create 3 distinct email templates for different key decision makers.\n",
        "    Each email should be:\n",
        "    - Personalized to their role\n",
        "    - Highlight relevant benefits\n",
        "    - Include a clear call to action\n",
        "    - Be concise and professional\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🔄 Email Writer Agent: Crafting email templates...\")\n",
        "    emails = llm.invoke(email_prompt)\n",
        "    print(\"✅ Email Writer Agent: Email templates completed\")\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [\n",
        "            {\"role\": \"assistant\", \"content\": \"Email templates generated\"}\n",
        "        ],\n",
        "        \"company_name\": state[\"company_name\"],\n",
        "        \"research\": state[\"research\"],\n",
        "        \"analysis\": state[\"analysis\"],\n",
        "        \"blog_post\": state[\"blog_post\"],\n",
        "        \"emails\": emails.content\n",
        "    }"
      ],
      "metadata": {
        "id": "zk3qNCPKWJrH"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define state management functions\n",
        "def get_company_name(state: AgentState) -> str:\n",
        "    return state[\"company_name\"]\n",
        "\n",
        "def build_graph():\n",
        "    \"\"\"Build the LangGraph workflow using StateGraph\"\"\"\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"research_node\", research_agent)\n",
        "    workflow.add_node(\"analysis_node\", analysis_agent)\n",
        "    workflow.add_node(\"blog_writer\", blog_writer_agent)\n",
        "    workflow.add_node(\"email_writer\", email_writer_agent)\n",
        "\n",
        "    # Define edges - Change the order of execution\n",
        "    workflow.add_edge(\"research_node\", \"analysis_node\")\n",
        "    workflow.add_edge(\"analysis_node\", \"blog_writer\")\n",
        "    # Only connect email_writer after blog_writer is done\n",
        "    workflow.add_edge(\"blog_writer\", \"email_writer\")\n",
        "\n",
        "    # Set the entry point\n",
        "    workflow.set_entry_point(\"research_node\")\n",
        "\n",
        "    # Set the final node\n",
        "    workflow.set_finish_point(\"email_writer\")\n",
        "\n",
        "    return workflow.compile()"
      ],
      "metadata": {
        "id": "EmjUY_fDbdK0"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_analysis():\n",
        "    \"\"\"Main application loop\"\"\"\n",
        "    global vectorstore\n",
        "    print(\"Initializing RAG system...\")\n",
        "    vectorstore = initialize_rag()\n",
        "\n",
        "    if vectorstore is None:\n",
        "        print(\"Please add documents to the 'uploads' folder and restart the application.\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        company_name = input(\"\\nEnter the name of the prospective organization: \")\n",
        "\n",
        "        graph = build_graph()\n",
        "\n",
        "        # Create initial state\n",
        "        initial_state = {\n",
        "            \"messages\": [{\n",
        "                \"content\": f\"Starting analysis for {company_name}\",\n",
        "                \"role\": \"user\",\n",
        "            }],\n",
        "            \"company_name\": company_name,\n",
        "            \"research\": {},\n",
        "            \"analysis\": \"\",\n",
        "            \"blog_post\": \"\",\n",
        "            \"emails\": \"\"\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            result = graph.invoke(initial_state)\n",
        "\n",
        "            # Display blog post with better error handling\n",
        "            print(\"\\n=== Generated Blog Post ===\")\n",
        "            if result and \"blog_post\" in result and result[\"blog_post\"]:\n",
        "                print(\"\\n\" + result[\"blog_post\"])\n",
        "            else:\n",
        "                print(\"No blog post was generated.\")\n",
        "                print(f\"Debug - Result keys: {result.keys() if result else 'No result'}\")\n",
        "\n",
        "            generate_emails = input(\"\\nWould you like to generate marketing emails? (yes/no): \")\n",
        "            if generate_emails.lower() == 'yes':\n",
        "                print(\"\\n=== Generated Email Templates ===\")\n",
        "                if result and \"emails\" in result and result[\"emails\"]:\n",
        "                    print(\"\\n\" + result[\"emails\"])\n",
        "                else:\n",
        "                    print(\"No email templates were generated.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during execution: {str(e)}\")\n",
        "\n",
        "        another = input(\"\\nWould you like to analyze another company? (yes/no): \")\n",
        "        if another.lower() != 'yes':\n",
        "            break"
      ],
      "metadata": {
        "id": "ar3vltmHayyY"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run_analysis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SqPBqAtV7kc",
        "outputId": "54e11501-17f5-4b80-8832-43aa22adbb41"
      },
      "execution_count": 95,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing RAG system...\n",
            "Processing documents:\n",
            "Reading royal_persicus.pdf...\n",
            "Successfully processed 1 documents into 1 chunks\n",
            "\n",
            "==================================================\n",
            "\n",
            "Enter the name of the prospective organization: IBM Canada\n",
            "\n",
            "🔍 Research Agent: Starting research for IBM Canada...\n",
            "✅ Research Agent: Successfully gathered company information\n",
            "\n",
            "🤔 Analysis Agent: Starting analysis of IBM Canada...\n",
            "📚 Analysis Agent: Retrieved relevant service information\n",
            "🔄 Analysis Agent: Generating analysis...\n",
            "✅ Analysis Agent: Analysis completed\n",
            "\n",
            "✍️ Blog Writer Agent: Starting blog post creation...\n",
            "Debug - Analysis available: True\n",
            "Debug - Analysis content preview: ### 1. Company's Current Challenges and Needs:\n",
            "\n",
            "IBM Canada is actively engaging in several innovative projects and expansions that highlight its current focus areas and implicit challenges. These incl\n",
            "🔄 Blog Writer Agent: Writing blog post...\n",
            "Debug - Blog post generated: True\n",
            "Debug - Blog post preview: # Empowering Innovation: How Royal Persicus Can Transform IBM Canada's Future\n",
            "\n",
            "## Executive Summary\n",
            "\n",
            "In the rapidly evolving tech landscape, IBM Canada stands out for its commitment to innovation, clo\n",
            "\n",
            "📧 Email Writer Agent: Starting email template creation...\n",
            "🔄 Email Writer Agent: Crafting email templates...\n",
            "✅ Email Writer Agent: Email templates completed\n",
            "\n",
            "=== Generated Blog Post ===\n",
            "\n",
            "# Empowering Innovation: How Royal Persicus Can Transform IBM Canada's Future\n",
            "\n",
            "## Executive Summary\n",
            "\n",
            "In the rapidly evolving tech landscape, IBM Canada stands out for its commitment to innovation, cloud expansion, and digital transformation. As they navigate these ambitious paths, the challenges of scalability, agility, and operational excellence become increasingly apparent. Royal Persicus, with its specialized services in SAFe transformation coaching, cloud adoption consulting, and digital transformation guidance, presents a strategic opportunity to empower IBM Canada's journey. This blog post delves into the alignment of our services with IBM Canada's needs and outlines a targeted approach strategy to initiate a partnership that drives future success.\n",
            "\n",
            "## Company Overview\n",
            "\n",
            "IBM Canada is at the forefront of technological innovation, focusing on the deployment of AI and the expansion of cloud services to foster digital transformation across industries. Their recent initiatives, such as the introduction of advanced AI models and the launch of a new Cloud Multizone Region in Montreal, highlight their ambition and the challenges that accompany such endeavors. As they strive to maintain their leadership position, the need for agile, scalable, and secure solutions becomes ever more critical.\n",
            "\n",
            "## Identified Needs and Challenges\n",
            "\n",
            "IBM Canada's commitment to innovation and digital transformation is evident in their strategic projects. However, these initiatives come with complex challenges:\n",
            "\n",
            "- The rapid development and deployment cycles for AI technologies demand an agile framework that can adapt and evolve.\n",
            "- Scaling cloud operations while ensuring reliability, security, and compliance poses a significant hurdle.\n",
            "- The overarching goal of digital transformation requires a holistic approach to innovate and improve business processes continually.\n",
            "\n",
            "## Our Solution Fit\n",
            "\n",
            "Royal Persicus is uniquely positioned to address IBM Canada's challenges:\n",
            "\n",
            "- **SAFe Transformation Coaching:** Our expertise can help IBM Canada implement agile practices at scale, enhancing their AI and cloud projects' efficiency and effectiveness.\n",
            "- **Cloud Adoption Consulting:** We offer strategic insights and practical solutions to navigate the complexities of cloud expansion, focusing on scalability, reliability, and cost-efficiency.\n",
            "- **Digital Transformation Guidance:** With a proven track record in driving digital transformations, we can assist IBM Canada in streamlining their efforts for long-term success and operational excellence.\n",
            "\n",
            "## Recommended Approach Strategy\n",
            "\n",
            "Our engagement strategy with IBM Canada focuses on demonstrating our value proposition through:\n",
            "\n",
            "- **Tailored Solutions Presentation:** Initiating contact with a clear understanding of IBM Canada's projects and presenting solutions that address their specific challenges.\n",
            "- **Leverage Success Stories:** Sharing our achievements in similar contexts to build credibility and showcase the impact of our services.\n",
            "- **Workshops and Demonstrations:** Offering hands-on sessions to provide immediate value and establish our commitment to practical, result-oriented solutions.\n",
            "- **Strategic Partnership Proposal:** Proposing a collaboration that addresses immediate needs while paving the way for future joint ventures in innovation and transformation.\n",
            "\n",
            "## Action Items\n",
            "\n",
            "1. **Research and Customize:** Develop a detailed understanding of IBM Canada's projects and tailor our solutions to meet their unique challenges.\n",
            "2. **Engage Key Decision-Makers:** Initiate contact with Dave McCann, Jose M. Selman, and Kevin McCabe to discuss strategic priorities and potential collaborations.\n",
            "3. **Prepare Success Stories:** Compile case studies and success stories that highlight our expertise and the benefits of our services.\n",
            "4. **Plan Workshops/Demos:** Design engaging workshops and demonstrations that showcase the value of our agile and cloud strategies.\n",
            "5. **Draft a Strategic Proposal:** Create a comprehensive proposal outlining a phased approach to partnership, emphasizing long-term benefits and alignment with IBM Canada's goals.\n",
            "\n",
            "By taking a strategic, value-driven approach to our engagement with IBM Canada, Royal Persicus can become an indispensable partner in their journey towards innovation, cloud expansion, and digital transformation. Together, we can pave the way for a future where technology transforms possibilities into realities.\n",
            "\n",
            "Would you like to generate marketing emails? (yes/no): yes\n",
            "\n",
            "=== Generated Email Templates ===\n",
            "\n",
            "### Email Template 1: To Dave McCann, President of IBM Canada\n",
            "\n",
            "Subject: Leveraging Agile for AI Innovation and Cloud Expansion at IBM Canada\n",
            "\n",
            "Dear Mr. McCann,\n",
            "\n",
            "I hope this message finds you well. I'm reaching out from Royal Persicus, where we specialize in facilitating agile transformations and digital innovation for forward-thinking organizations like IBM Canada.\n",
            "\n",
            "Your recent initiatives, particularly the pioneering of AI technologies and the expansion of cloud services, are commendable. At Royal Persicus, we recognize the complexities and challenges that accompany such ambitious projects. Our SAFe transformation coaching and cloud adoption consulting services are designed to address these very challenges, ensuring a smooth, scalable, and successful digital evolution.\n",
            "\n",
            "We believe our expertise can complement IBM Canada's strategic goals, particularly by enhancing the agility of your AI development cycles and supporting your cloud infrastructure expansion with robust, efficient strategies.\n",
            "\n",
            "Could we schedule a brief meeting to discuss how Royal Persicus can help IBM Canada stay ahead in this rapidly changing digital landscape? I'm confident that together, we can achieve remarkable results.\n",
            "\n",
            "Thank you for considering this opportunity. I look forward to the possibility of collaborating with you.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Position]  \n",
            "Royal Persicus  \n",
            "[Your Contact Information]\n",
            "\n",
            "---\n",
            "\n",
            "### Email Template 2: To Jose M. Selman, IBM Cloud Technical Sales Manager - Canada\n",
            "\n",
            "Subject: Empowering IBM Canada’s Cloud Strategy with Expert Consulting\n",
            "\n",
            "Dear Mr. Selman,\n",
            "\n",
            "Greetings from Royal Persicus. As IBM Canada continues to lead in cloud services expansion, I wanted to reach out and introduce how our cloud adoption consulting could further enhance your projects' success.\n",
            "\n",
            "Your role in steering IBM Canada's cloud technical sales is pivotal. At Royal Persicus, we have a proven track record of helping large organizations navigate the complexities of cloud scalability, security, and efficiency. Our strategic consulting services are tailored to ensure that cloud transformations are not just successful but also sustainable and future-proof.\n",
            "\n",
            "Given your expertise, I believe a collaboration could significantly benefit IBM Canada’s cloud initiatives. Would you be open to a conversation about how we can support your goals and address any challenges you're facing?\n",
            "\n",
            "Thank you for considering this partnership. I look forward to the opportunity to discuss how we can work together to achieve even greater success in your cloud endeavors.\n",
            "\n",
            "Warm regards,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Position]  \n",
            "Royal Persicus  \n",
            "[Your Contact Information]\n",
            "\n",
            "---\n",
            "\n",
            "### Email Template 3: To Kevin McCabe, IBM Cloud Leader - Canada\n",
            "\n",
            "Subject: Enhancing IBM Canada’s Cloud Journey with Proven Strategies\n",
            "\n",
            "Dear Mr. McCabe,\n",
            "\n",
            "I hope this email finds you well. At Royal Persicus, we’ve been closely following IBM Canada’s strategic moves towards expanding its cloud infrastructure and couldn’t help but reach out to you.\n",
            "\n",
            "Your leadership in IBM Canada’s cloud initiatives is inspiring. As experts in cloud adoption and digital transformation, we at Royal Persicus offer specialized consulting that aligns perfectly with IBM Canada’s objectives. Our approach focuses on ensuring scalability, reliability, and regulatory compliance, addressing the very challenges that come with ambitious cloud expansions.\n",
            "\n",
            "I am keen to explore how our consultancy can add value to your projects and facilitate IBM Canada’s growth in this area. Could we schedule a call or meeting to discuss potential synergies and how we can support your vision for IBM Canada’s cloud future?\n",
            "\n",
            "Thank you for considering this. I am looking forward to possibly starting a conversation that could lead to significant achievements for IBM Canada.\n",
            "\n",
            "Best wishes,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Position]  \n",
            "Royal Persicus  \n",
            "[Your Contact Information]\n",
            "\n",
            "Would you like to analyze another company? (yes/no): yes\n",
            "\n",
            "==================================================\n",
            "\n",
            "Enter the name of the prospective organization: Bell Canada\n",
            "\n",
            "🔍 Research Agent: Starting research for Bell Canada...\n",
            "✅ Research Agent: Successfully gathered company information\n",
            "\n",
            "🤔 Analysis Agent: Starting analysis of Bell Canada...\n",
            "📚 Analysis Agent: Retrieved relevant service information\n",
            "🔄 Analysis Agent: Generating analysis...\n",
            "✅ Analysis Agent: Analysis completed\n",
            "\n",
            "✍️ Blog Writer Agent: Starting blog post creation...\n",
            "Debug - Analysis available: True\n",
            "Debug - Analysis content preview: Given the information provided about Bell Canada and the services offered by Royal Persicus, let's delve into a detailed analysis addressing the specified points:\n",
            "\n",
            "### 1. Company's Current Challenges \n",
            "🔄 Blog Writer Agent: Writing blog post...\n",
            "Debug - Blog post generated: True\n",
            "Debug - Blog post preview: # Empowering Bell Canada's Future: Agile and Cloud Solutions for Sustainable Growth\n",
            "\n",
            "## Executive Summary\n",
            "In an era of rapid digital transformation and sustainability commitments, Bell Canada, the nat\n",
            "\n",
            "📧 Email Writer Agent: Starting email template creation...\n",
            "🔄 Email Writer Agent: Crafting email templates...\n",
            "✅ Email Writer Agent: Email templates completed\n",
            "\n",
            "=== Generated Blog Post ===\n",
            "\n",
            "# Empowering Bell Canada's Future: Agile and Cloud Solutions for Sustainable Growth\n",
            "\n",
            "## Executive Summary\n",
            "In an era of rapid digital transformation and sustainability commitments, Bell Canada, the nation's largest communications company, stands at the forefront of innovation and expansion. This blog post dives into Bell Canada's journey towards enhancing its network infrastructure, adopting agile methodologies, and achieving remarkable sustainability goals. It further explores how Royal Persicus's expertise in SAFe transformation coaching and cloud adoption consulting aligns with Bell Canada's strategic objectives, offering a roadmap to accelerated growth and operational efficiency.\n",
            "\n",
            "## Company Overview\n",
            "Bell Canada has established itself as a leader in the telecommunications industry, renowned for its vast array of services including internet, wireless, TV, and media. The company's commitment to growth is evident through strategic acquisitions and partnerships, alongside significant investments in broadband and 5G technologies. As Bell Canada strives to meet the evolving needs of its customers, the demand for scalable, agile, and technology-driven solutions has never been more critical.\n",
            "\n",
            "## Identified Needs and Challenges\n",
            "Bell Canada is navigating through an era of unprecedented change, facing several challenges head-on:\n",
            "- **Scalability and Agility:** With ongoing expansion, the need for scalable operations and the adoption of agile methodologies is paramount to maintain competitiveness.\n",
            "- **Digital Transformation:** Continuous technological advancements necessitate a robust strategy for digital transformation, ensuring seamless integration and operation.\n",
            "- **Sustainability and Efficiency:** Bell Canada's commitment to carbon neutrality and science-based sustainability targets requires efficient technology and resource utilization.\n",
            "\n",
            "## Our Solution Fit\n",
            "Royal Persicus offers tailor-made solutions that address Bell Canada's core needs:\n",
            "- **SAFe Transformation Coaching:** Our approach to agile practices at scale will enhance Bell Canada's project alignment, collaboration, and delivery capabilities, directly impacting its scalability and agility.\n",
            "- **Cloud Adoption Consulting:** Our cloud strategy expertise will support Bell Canada's digital transformation journey, promoting operational efficiency, cost-effectiveness, and sustainability.\n",
            "\n",
            "## Recommended Approach Strategy\n",
            "To effectively engage with Bell Canada and demonstrate the value of Royal Persicus's services, we propose:\n",
            "1. **Tailored Presentations:** Customized presentations that resonate with Bell Canada's strategic goals, showcasing our alignment and solution offerings.\n",
            "2. **Pilot Projects:** Initiating pilot projects to provide tangible evidence of the benefits associated with agile transformation and cloud adoption.\n",
            "3. **Sustainability Integration:** Emphasizing how our services not only support digital transformation but also Bell Canada's sustainability ambitions.\n",
            "4. **Partnership Approach:** Fostering a relationship based on collaboration, long-term support, and shared success.\n",
            "5. **Leverage Success Stories:** Sharing relevant case studies that highlight the measurable benefits and long-term value of our services.\n",
            "\n",
            "## Action Items\n",
            "To embark on this transformative journey with Bell Canada, Royal Persicus will:\n",
            "- Schedule meetings with key decision-makers including the CIO, CTO, and CSO to understand their specific goals and challenges.\n",
            "- Develop a comprehensive proposal that includes tailored presentations, outlines potential pilot projects, and demonstrates our commitment to sustainability and partnership.\n",
            "- Organize workshops and seminars to further engage with Bell Canada's teams, providing insights into agile methodologies and cloud technologies.\n",
            "\n",
            "By aligning our services with Bell Canada's strategic objectives, Royal Persicus is poised to play a pivotal role in their journey towards enhanced scalability, digital transformation, and sustainability. Together, we can achieve remarkable growth, operational excellence, and a sustainable future.\n",
            "\n",
            "Would you like to generate marketing emails? (yes/no): yes\n",
            "\n",
            "=== Generated Email Templates ===\n",
            "\n",
            "### Email Template for the Chief Information Officer (CIO)\n",
            "\n",
            "**Subject:** Transforming Bell Canada's Operations with Agile and Cloud Solutions\n",
            "\n",
            "Dear [CIO's Name],\n",
            "\n",
            "I hope this message finds you well. As Bell Canada continues to lead in telecommunications, we recognize the challenges and opportunities that come with managing your expansive operations and ambitious growth plans. At Royal Persicus, we specialize in empowering organizations like yours through SAFe Transformation Coaching and Cloud Adoption Consulting to enhance operational efficiency and innovation.\n",
            "\n",
            "**Why This Matters for You:** The agility to adapt and scale is critical in today's fast-paced digital landscape. Our SAFe Transformation Coaching can streamline your project management and delivery processes, enabling Bell Canada to respond more swiftly to market changes and customer needs. Additionally, our Cloud Adoption Consulting offers a roadmap to leverage cutting-edge cloud technologies, ensuring your digital infrastructure is robust, scalable, and cost-effective.\n",
            "\n",
            "We are keen on discussing how our tailored solutions can specifically address your strategic objectives and help Bell Canada maintain its competitive edge. Would you be available for a brief meeting next week to explore this further?\n",
            "\n",
            "Thank you for considering this opportunity to enhance Bell Canada's technological direction. I look forward to the possibility of working together towards your digital transformation goals.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Position]  \n",
            "Royal Persicus  \n",
            "[Contact Information]\n",
            "\n",
            "---\n",
            "\n",
            "### Email Template for the Chief Technology Officer (CTO)\n",
            "\n",
            "**Subject:** Accelerating Bell Canada's Network and Digital Transformation\n",
            "\n",
            "Dear [CTO's Name],\n",
            "\n",
            "As Bell Canada propels forward with its broadband and 5G expansion, the importance of embracing innovative technologies and methodologies has never been greater. At Royal Persicus, we understand the intricacies involved in network acceleration and digital transformation and are here to offer our expertise in Cloud Adoption and Agile Practices.\n",
            "\n",
            "**Benefit to Your Role:** With your focus on technological advancements and infrastructure expansion, our services directly align with your mission. Our cloud adoption strategies can significantly enhance your digital infrastructure's performance and resilience, while our approach to agile practices at scale will streamline project execution and delivery.\n",
            "\n",
            "Considering the ambitious goals you've set for Bell Canada, I believe a conversation on how we can support your digital transformation journey would be mutually beneficial. May I suggest a meeting to discuss this in more detail?\n",
            "\n",
            "Looking forward to the opportunity to contribute to Bell Canada's technological advancements.\n",
            "\n",
            "Warm regards,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Position]  \n",
            "Royal Persicus  \n",
            "[Contact Information]\n",
            "\n",
            "---\n",
            "\n",
            "### Email Template for the Chief Sustainability Officer (CSO)\n",
            "\n",
            "**Subject:** Supporting Bell Canada's Sustainability Goals Through Digital Transformation\n",
            "\n",
            "Dear [CSO's Name],\n",
            "\n",
            "Achieving Bell Canada's commitment to carbon neutrality and setting science-based targets is a testament to your leadership in corporate sustainability. At Royal Persicus, we are passionate about supporting organizations to meet their environmental goals through efficient and sustainable digital transformation strategies.\n",
            "\n",
            "**How We Can Help:** Our SAFe Transformation Coaching and Cloud Adoption Consulting are designed not only to streamline operations and foster innovation but also to reduce environmental impact. By optimizing resource utilization and enhancing operational efficiencies, we can help Bell Canada move closer to its sustainability objectives.\n",
            "\n",
            "I am eager to explore how our services can align with your sustainability goals and contribute to Bell Canada's greener future. Could we schedule a time to discuss this further?\n",
            "\n",
            "Thank you for your dedication to making a difference. I look forward to the possibility of contributing to your sustainability efforts.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Position]  \n",
            "Royal Persicus  \n",
            "[Contact Information]\n",
            "\n",
            "Would you like to analyze another company? (yes/no): no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x17J4a7Kc-U0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}